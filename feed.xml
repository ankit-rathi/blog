<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://ankit-rathi.github.io/data-and-ai/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ankit-rathi.github.io/data-and-ai/" rel="alternate" type="text/html" /><updated>2020-05-23T06:38:10-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/feed.xml</id><title type="html">Data &amp;amp; AI Stories</title><subtitle>From Data To Actionable Insights</subtitle><entry><title type="html">Data &amp;amp; AI Session @ RBS</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/23/data-ai-session-rbs.html" rel="alternate" type="text/html" title="Data &amp; AI Session @ RBS" /><published>2020-05-23T00:00:00-05:00</published><updated>2020-05-23T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/23/data-ai-session-rbs</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/23/data-ai-session-rbs.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1800/1*ywKDU1YOOWCW0MnSMflpLA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*xjdch6IXdtsDOngEyNAckw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*5EbwVka2P8eYnUrB2qil-A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*8CkDJRNtAPthaF4scY2PKw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*O9SQNWU9Livy_Buve1bG-A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*YjbXVlzKMX4812rBj4sThw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*PcPxxChbLvs5iIdJ2YpSgw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*4EcBeWye10ebr7m85da2cA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*f62g1k4-jLJ_xElSUPV1yQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*2WlBT0L64qAf1Z3xH_mstQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*k2DfCg0onmqs2-RYPbZJwQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*p2s_DAsKz7gd8ZxzzMT3dA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*ZXrK7DUHTgordrmKKP7OUQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*D55JToAE2ptrz7x3Co4lSA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*iLsFhQ3Mv-xlY0vbY_bRwg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*1tycTNUk1K_o9K_WabosSg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*xxwvp6FA0eGWfHa9vpqK8w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*1h1YNkaH68QXOPAmd2FhcQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*OqrWTkpiCgfdBWJ96ipZOA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Data Professionals, and NOT Data Scientist, is the Job of the Century</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/20/data-professionals-is-the-job-of-the-century.html" rel="alternate" type="text/html" title="Data Professionals, and NOT Data Scientist, is the Job of the Century" /><published>2020-05-20T00:00:00-05:00</published><updated>2020-05-20T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/20/data-professionals-is-the-job-of-the-century</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/20/data-professionals-is-the-job-of-the-century.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1800/1*WeT4WJgyl0gOIH4AP8GjUA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Grab the content on your favorite platform:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;on YouTube: &lt;a href=&quot;https://www.youtube.com/watch?v=W_6Q0jLjTdY&quot;&gt;https://www.youtube.com/watch?v=W_6Q0jLjTdY&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;on SlideShare: &lt;a href=&quot;https://www.slideshare.net/ankitrathi/data-professionals-job-of-the-century&quot;&gt;https://www.slideshare.net/ankitrathi/data-professionals-job-of-the-century&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;on GitHub Pages: &lt;a href=&quot;https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/20/data-professionals-is-the-job-of-the-century.html&quot;&gt;https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/20/data-professionals-is-the-job-of-the-century.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*fOkMPFN71hazH-YqRQ2jSA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*duQ1HBHs7TeKKd44YJI_xQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*_IZfKWucF0J1s6uOaidchw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*NJ36OkZcCsIxI4J7eTS4UQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*MUUyy7f92vfsLNwbeoGt9A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*LWalRZ-Mq1DY8vfO3SbbUg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*ACXqf5YTiTBkEvdTj2e_sA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*wt5kF0UEeygl8OjLm52XZA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*0RCZRwXzxap_4B3H2tNz_A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*REf3HfZkEpA6I5JOV_scVw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*88o1GL6ZiPGg0P2bx6CSog.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*-AsRiux3mBdngeGKzvlBZQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*73WU9IecDAKiLTdHmZbQIA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*EM2y_YNdwFdxZzcqVOIj2Q.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*gbGDL6DQETTW5-pQB32TfQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*wD_lh5Eb57iZKVEkem7Unw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*N4OoxaHpT12IgTVrlNzg4w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*DqY9jNX-rNPP9WEwd1MsPQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*6tmV4vuJ5qCIpkXZSVUB5Q.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*VSc-tYwFjamg9CG5X66mEQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*dyxg2y2jM6HIZy-5GOOjmQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*lyAbYCwKOqacZAdIs-Ubuw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*ywHNwWI_19qGQJqakvK1ag.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*Hbxp6n7h5RPWWNhpINLitA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*J2jp766CTVRen_C7WOIzBA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*tzRWl0gtMais1br0q1sWww.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*lT3tE5E80iaHkbYjf8jzww.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*fphhr0mnUBY37NZwhHUYSA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*9N2YgCEJRqRjtMxoIH6UYw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*e4D3gp-IWmS57kY05s83mA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*SrsuVZAEkno9BxDtWErj_w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*YrZig1GwY7HtJ6TZrSSXMw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*6VFe8nKN1yl5a_m1BZ6dVA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*MUUyy7f92vfsLNwbeoGt9A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*Rp3a7f2EptbQ7gqm5RAuZA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Cloud Computing for Data Professionals</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/15/cloud-computing-for-data-professionals.html" rel="alternate" type="text/html" title="Cloud Computing for Data Professionals" /><published>2020-05-15T00:00:00-05:00</published><updated>2020-05-15T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/15/cloud-computing-for-data-professionals</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/15/cloud-computing-for-data-professionals.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1800/1*EjtLBNb-eHNvzBe9nAu9Yw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*uAInIpx3fSlDdZ7GaYrJ4Q.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*YG19n8uEBaUdVe0qqfVy4Q.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*0RohJO9gc3fH0mDSsR0J4w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*x3Moi8LjMpUpjQHCB-SHug.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*WdaBG3aglBWcmLvZYr04dQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*3S_hR7Gy_aYwqNGRe8FFZQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*MfKZRcEJ2eUUmMS-x4tG_w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*2XMzgJadQd_sO92YAMsdvw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*KD9aYQ3uYrf6Jq5sRss1qw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*KnXRrTfqwhjkqx1St50Txg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*WGt1drIJvIXuLuxqqDHMtQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*EALetV-rbsjO3-7DEOZLgg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*cDI3hrXIKatwbfZkBL_3Pw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*wZs2RInYfOFkFSGYqf3GcA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*de3ZU_DMrXICaaMJ2WjtvA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*ijBeWmH8Wa7fEZJPhuqgHw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*OJiko0eQ0N2_kv1HjUiqlQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Becoming Data &amp;amp; AI Specialist on AWS Platform (for free)</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/10/Becoming-Data-AI-Specialist-on-AWS-Platform.html" rel="alternate" type="text/html" title="Becoming Data &amp; AI Specialist on AWS Platform (for free)" /><published>2020-05-10T00:00:00-05:00</published><updated>2020-05-10T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/10/Becoming-Data-AI-Specialist-on-AWS-Platform</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/10/Becoming-Data-AI-Specialist-on-AWS-Platform.html">&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/2000/1*CR5IbBW_wvl24ckGgzHwCA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The demand for the workforce to be able to operate in the cloud is growing exponentially. Many cloud providers themselves (i.e. AWS, Azure &amp;amp; GCP) offer easy access to the new generation of cloud training, for professionals and enterprise.&lt;/p&gt;

&lt;h2 id=&quot;aws-learning-library&quot;&gt;AWS Learning Library&lt;/h2&gt;
&lt;p&gt;The AWS Learning Library is a hub of highly-rated resources including learning paths, courses, labs, quizzes, and exams to enable you to get the right training to put you on the right track for AWS success.&lt;/p&gt;

&lt;p&gt;There are plenty of resources available to learn about AWS Data &amp;amp; AI services for free.&lt;/p&gt;

&lt;h2 id=&quot;aws-cloud-essentials&quot;&gt;AWS Cloud Essentials&lt;/h2&gt;
&lt;p&gt;Learn about the foundations of getting started in the AWS Cloud. In this course, you learn about the AWS Cloud architecture and the services in the Compute, Storage, Database, Networking, and Security categories. This course can help you can build and validate an overall understanding of the AWS Cloud, key terminology, and help advance your AWS Cloud skills.&lt;/p&gt;

&lt;p&gt;In this course, you will learn to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Describe the AWS Cloud value proposition&lt;/li&gt;
  &lt;li&gt;Describe the basic global infrastructure of the cloud&lt;/li&gt;
  &lt;li&gt;Describe and differentiate between AWS service domains&lt;/li&gt;
  &lt;li&gt;Explain the Shared Responsibility model&lt;/li&gt;
  &lt;li&gt;Describe AWS pricing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can access this e-Learning session here:
&lt;a href=&quot;https://www.aws.training/Details/Video?id=49639&quot;&gt;https://www.aws.training/Details/Video?id=49639&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;aws-machine-learning-specialty&quot;&gt;AWS Machine Learning Specialty&lt;/h2&gt;
&lt;p&gt;This course prepares you to take the AWS Certified Machine Learning — Specialty exam, which validates your ability to design, implement, deploy, and maintain machine learning (ML) solutions.&lt;/p&gt;

&lt;p&gt;In this course, you’ll learn about the logistics of the exam and the mechanics of exam questions, and you’ll explore the exam’s technical domains. You’ll review core AWS services and key concepts for the exam domains:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Data Engineering&lt;/li&gt;
  &lt;li&gt;Exploratory Data Analysis&lt;/li&gt;
  &lt;li&gt;Modeling&lt;/li&gt;
  &lt;li&gt;Machine Learning Implementation and Operations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You’ll also learn key test-taking strategies and will put them into action, taking multiple study questions. Once you’ve honed your skills, you’ll have the chance to take a quiz that will help you assess your areas of strength and weakness, so that you’ll know what to emphasize in your pre-exam studies.&lt;/p&gt;

&lt;p&gt;You can access this e-Learning session here:
&lt;a href=&quot;https://www.aws.training/Details/eLearning?id=42183&quot;&gt;https://www.aws.training/Details/eLearning?id=42183&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;aws-data-analytics-speciality&quot;&gt;AWS Data Analytics Speciality&lt;/h2&gt;
&lt;p&gt;The AWS Certified Data Analytics — Specialty exam validates technical skills and experience in designing and implementing AWS services to derive value from data. This course helps you prepare for the exam by exploring the exam’s topic areas and familiarizing you with the question style and exam approach. The course reviews sample exam questions in each topic area and teach you how to interpret the concepts being tested so you can more easily eliminate incorrect responses.&lt;/p&gt;

&lt;p&gt;The course addresses each of the exam’s content domains:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Data collection systems&lt;/li&gt;
  &lt;li&gt;Storage and data management concerns&lt;/li&gt;
  &lt;li&gt;Data processing solutions&lt;/li&gt;
  &lt;li&gt;Analysis and visualization of analytical data&lt;/li&gt;
  &lt;li&gt;Security of the data analysis system&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can access this e-Learning session here:
&lt;a href=&quot;https://www.aws.training/Details/eLearning?id=46612&quot;&gt;https://www.aws.training/Details/eLearning?id=46612&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;aws-database-specialty&quot;&gt;AWS Database Specialty&lt;/h2&gt;
&lt;p&gt;The AWS Certified Database — Specialty exam validates technical skills and experience in designing, deploying, and managing AWS database services. This course helps you prepare for the exam by exploring the exam’s topic areas and familiarizing you with the question style and exam approach. The course reviews sample exam questions in each topic area and teach you how to interpret the concepts being tested so you can more easily eliminate incorrect responses.&lt;/p&gt;

&lt;p&gt;The course addresses each of the exam’s content domains:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Workload-specific database design&lt;/li&gt;
  &lt;li&gt;Deployment and migration&lt;/li&gt;
  &lt;li&gt;Management and operations&lt;/li&gt;
  &lt;li&gt;Monitoring and troubleshooting&lt;/li&gt;
  &lt;li&gt;Database security&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can access this e-Learning session here:
&lt;a href=&quot;https://www.aws.training/Details/eLearning?id=47245&quot;&gt;https://www.aws.training/Details/eLearning?id=47245&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;exploring-aws-free-tier&quot;&gt;Exploring AWS Free Tier&lt;/h2&gt;
&lt;p&gt;You can explore more than 60 products and start building on AWS using the free tier. Three different types of free offers are available depending on the product used. See below for details on each product.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Always free&lt;/li&gt;
  &lt;li&gt;12 months free&lt;/li&gt;
  &lt;li&gt;Trials&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can have a look at these services here:
&lt;a href=&quot;https://aws.amazon.com/free/&quot;&gt;https://aws.amazon.com/free/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In my upcoming posts, I will cover how you can learn about Data &amp;amp; AI services available on GCP &amp;amp; Azure for free.&lt;/p&gt;

&lt;p&gt;This is it for now, I hope you liked this article, stay tuned for more.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">A Brief History of Data Systems</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/05/A-Brief-History-of-Data-Systems.html" rel="alternate" type="text/html" title="A Brief History of Data Systems" /><published>2020-05-05T00:00:00-05:00</published><updated>2020-05-05T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/05/A-Brief-History-of-Data-Systems</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/05/05/A-Brief-History-of-Data-Systems.html">&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1500/1*qb6OpIgxPAZcvN54UCa1Bg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;
&lt;p&gt;Many a time it happens when our business or customer wants to implement Big Data approaches exploiting AI use cases. But they completely get lost in the number of buzzwords like Data Lake, Lambda Architecture etc.&lt;/p&gt;

&lt;p&gt;In the past, I have prepared material for such business stakeholders and customers to build their foundation on data systems so that they can understand these buzzwords in a simplest non-technical manner.&lt;/p&gt;

&lt;p&gt;Most of the time I ended up explaining how it all started and which approach or design pattern emerged or disappeared for what reason. So in this blog-post, I am trying to provide a brief history of how the data systems have evolved.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Almost all the definitions added here to further explain the terms used have been referenced from Wikipedia.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;single-user&quot;&gt;Single User&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*AHvicv5x0WXYjQK5sLottw.png&quot; alt=&quot;&quot; /&gt;
Data systems’ journey started with a single user, a simple application running on a single machine.&lt;/p&gt;

&lt;h2 id=&quot;client-server&quot;&gt;Client-Server&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*dQ5r8_lZezy537XAvSWY3A.png&quot; alt=&quot;&quot; /&gt;
When multiple users needed to access data on the same server, Client-Server architecture followed, a thin client on the user’s machine connected to the server.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Client–server model is a distributed application structure that partitions tasks or workloads between the providers of a resource or service, called servers, and service requesters, called clients.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;front-end--back-end&quot;&gt;Front End &amp;amp; Back End&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*yAJLS80AY_0nPnZmNLZzIg.png&quot; alt=&quot;&quot; /&gt;
Over time, to better manage the users &amp;amp; data system, server further divided into front-end and backend, backend dealing with data and frontend tackling with users.&lt;/p&gt;

&lt;h2 id=&quot;database&quot;&gt;Database&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*_tjVhK_vVFX0HsAaBdwJIw.png&quot; alt=&quot;&quot; /&gt;
Database introduced to manage data efficiently and to allow users to perform multiple tasks with ease.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A database management system (DBMS) stores, organizes and manages a large amount of information within a single software application.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;business-intelligence&quot;&gt;Business Intelligence&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*iGP038MJc0mKxhAFmqqV3w.png&quot; alt=&quot;&quot; /&gt;
Business Intelligence (BI) function added at the other end of the database to get insights from operational data, till now this was all on a single machine.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Business Intelligence comprises the strategies and technologies used by enterprises for the data analysis of business information. BI technologies provide historical, current, and predictive views of business operations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;more-users&quot;&gt;More Users&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*8QvkdkxdLbxhRc64V7cJkA.png&quot; alt=&quot;&quot; /&gt;
As users increased on the operational side, the single machine got split into two to manage different operational and analytical needs of the users.&lt;/p&gt;

&lt;h2 id=&quot;even-more-users&quot;&gt;Even More Users&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*wazIo-VpWaNh0faF0Iutwg.png&quot; alt=&quot;&quot; /&gt;
As more users increased on the operational side, machines were added in parallel to manage the load.&lt;/p&gt;

&lt;h2 id=&quot;automated-systems&quot;&gt;Automated Systems&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*w62o7HXmvXWlfDVfz5u0BA.png&quot; alt=&quot;&quot; /&gt;
Addition of automated systems also put pressure on the database, BI layer got split to better manage BI concerns separately.&lt;/p&gt;

&lt;h2 id=&quot;more-users-analytics&quot;&gt;More Users (Analytics)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*q9hbUPs4YXDut1egCBv3tg.png&quot; alt=&quot;&quot; /&gt;
To manage the operational load, even databases were made available in parallel, which increased the load on BI, as well as introduced few problems in terms of inconsistency.&lt;/p&gt;

&lt;h2 id=&quot;etl--dwh&quot;&gt;ETL &amp;amp; DWH&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*GSgJyJ7TPgh4KYaYHYCDFQ.png&quot; alt=&quot;&quot; /&gt;
DWH and ETL layer allowed the consolidation of data, analysis and reporting for analytical users.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A data warehouse (DWH)is designed to support business decisions by allowing data consolidation, analysis and reporting at different aggregate levels.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The process of extracting data from source systems and bringing it into the data warehouse is commonly called ETL, which stands for extraction, transformation, and loading.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;data-mining--olap&quot;&gt;Data Mining &amp;amp; OLAP&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*hTQJa81UrstbTyEB4XVLKw.png&quot; alt=&quot;&quot; /&gt;
As time progressed, analytical needs increased, data mining (DM) and online analytical processing (OLAP) functions added.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Data mining (DM) is the process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;extract-load-transform-elt&quot;&gt;Extract, Load, Transform (ELT)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*s1m20XDpuWJb795c4lxLOw.png&quot; alt=&quot;&quot; /&gt;
To reduce the dependencies on source data systems and minimize the latency, ELT pattern started being used.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Extract, load, transform (ELT) is an alternative to extract, transform, load (ETL) used with data warehouse or data lake implementations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;change-data-capture-cdc&quot;&gt;Change Data Capture (CDC)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*V4eWusR-iJDziYCbb4hldA.png&quot; alt=&quot;&quot; /&gt;
To further reduce the latency, change data capture (CDC) pattern introduced to transfer only the change-log rather actual data.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Change data capture (CDC) is a set of software design patterns used to determine and track the data that has changed so that action can be taken using the changed data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;data-lake-hadoopspark&quot;&gt;Data Lake (Hadoop/Spark)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*4yZ-SS7refneWOA8FVqSgQ.png&quot; alt=&quot;&quot; /&gt;
As analytics needs of organizations increased with less and less time-to-market as well as latency requirements, Data Lake was introduced to make the most of the rapidly evolving technologies like Hadoop and Spark.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A data lake is usually a single store of all enterprise data including raw copies of source system data and transformed data used for tasks such as reporting, visualization, advanced analytics and machine learning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Apache Hadoop is a collection of open-source software utilities that facilitate using a network of many computers to solve problems involving massive amounts of data and computation. It provides a software framework for distributed storage and processing of big data using the MapReduce programming model.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Apache Spark is an open-source distributed general-purpose cluster-computing framework. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;data-science-mlai&quot;&gt;Data Science (ML/AI)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*FF8RD-yLGLJjLcq_GkFNIQ.png&quot; alt=&quot;&quot; /&gt;
Due to recent advancement in the field of Artificial Intelligence, along with traditional analytics needs like BI, organizations started looking to leverage ML/DL use cases to gain competitive advantage.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Data Science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Machine Learning is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Artificial Intelligence, sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;lambda-architecture&quot;&gt;Lambda Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*Hgw-w8SRaEueIGo96D7SKQ.png&quot; alt=&quot;&quot; /&gt;
Along with batch processing and analytics, real-time processing and analytics also started gaining grounds. To eliminate the inconsistencies and overheads, Lambda Architecture was introduced.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lambda architecture is a data-processing architecture designed to handle massive quantities of data by taking advantage of both batch and stream-processing methods.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;kappa-architecture&quot;&gt;Kappa Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*XOQxRJ-jCg4gwaAWYuEFWA.png&quot; alt=&quot;&quot; /&gt;
Lambda Architecture brings some complexities with it, Kappa Architecture is a simplification of Lambda Architecture.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A Kappa Architecture system is like a Lambda Architecture system with the batch processing system removed. To replace batch processing, data is simply fed through the streaming system quickly.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;delta-lake&quot;&gt;Delta Lake&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*N-NLV7xVVmZM17visqfZJw.png&quot; alt=&quot;&quot; /&gt;
While Data Lakes are prominent in modern data architecture, it has its own problems. One of the major problems is lack of ACID capabilities, this problem has been solved by Delta Lake.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Delta Lake is an open source storage layer that brings reliability to data lakes. Delta Lake provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing. Delta Lake runs on top of your existing data lake and is fully compatible with Apache Spark APIs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;distributed-data-mesh&quot;&gt;Distributed Data Mesh&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1050/1*bgIloMVtrlDTIjRDIDZF8g.png&quot; alt=&quot;&quot; /&gt;
Data Lake and even Delta Lake still have some common failure mode, one of the most talked-about failures is centralized and siloed nature which substantially hampers the capability to make data and its business value made available across the organization.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Distributed Data Mesh is an architectural paradigm that unlocks analytical data at scale; rapidly unlocking access to an ever-growing number of distributed domain data sets, for a proliferation of consumption scenarios such as machine learning, analytics or data-intensive applications across the organization.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;concluding-thoughts&quot;&gt;Concluding Thoughts&lt;/h2&gt;

&lt;p&gt;This is it for now, as you may notice that Data Systems are evolving rapidly of late. In my view, there are two takeaways of this post:&lt;/p&gt;

&lt;p&gt;Not one size fits all, which component or framework to use, it all depends on your specific requirement.&lt;/p&gt;

&lt;p&gt;Even the latest approaches have inherent drawbacks (i.e. Data Lake, Distributed Data Mesh), the field will keep evolving and will be coming up with advanced methodologies.&lt;/p&gt;

&lt;p&gt;I believe you found this blog-post helpful, do provide your valuable feedback.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">From Data To Actionable Insights</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/30/From-Data-To-Actionable-Insights.html" rel="alternate" type="text/html" title="From Data To Actionable Insights" /><published>2020-04-30T00:00:00-05:00</published><updated>2020-04-30T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/30/From-Data-To-Actionable-Insights</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/30/From-Data-To-Actionable-Insights.html">&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/2000/1*vJu3xpSgK6X0T_jfUnh5_A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Data is the new oil, AI is the new electricity.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You may keep hearing these terms of late. As Data &amp;amp; AI field is gaining immense traction, every organization or business is looking to make the most of the opportunities available to them.&lt;/p&gt;

&lt;p&gt;Many of you may be working on relevant projects as well, where you collect, store, process, analyse data, and serve the insights to business stakeholders. Some of you may be using the latest ML/AI techniques in your projects and may be aware of CRISP-DM technique.&lt;/p&gt;

&lt;p&gt;If you are working on a one-off project in the AI/ML area, it is fine to just get the work done but if you have many use-cases, it makes sense to have a streamlined approach, for data ingestion, storage, processing and service, so that common resources (data, pipelines, infra etc) can be used across use cases. That’s where design, architecture &amp;amp; governance come into the picture.&lt;/p&gt;

&lt;p&gt;In this article, I would like to show you the typical design of data-intensive applications using a data platform.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Data &amp;amp; AI being a vast field having many sub-fields, a single post is not enough to explain each component to sufficient depth, so I will cover the in-depth view of each component/function in upcoming posts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;data--actionable-insights&quot;&gt;Data &amp;amp; Actionable Insights&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*T1WfVLbR0uwfNzBEhQBmtw.png&quot; alt=&quot;&quot; /&gt;
On the highest level of abstraction, you can see a data &amp;amp; AI system as a black box, where data goes in and actionable insights come out. Let’s look at what’s there in this black-box.&lt;/p&gt;

&lt;h2 id=&quot;core--support-functions&quot;&gt;Core &amp;amp; Support Functions&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*AX1iXOcu0SFMKPVd21rvLA.png&quot; alt=&quot;&quot; /&gt;
If you look into this black-box, you can see that there are some core functions and some support functions to transform data into actionable insights. Core functions work on data while support functions manage and optimize core functions.&lt;/p&gt;

&lt;h2 id=&quot;understanding-the-big-picture&quot;&gt;Understanding the Big Picture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*yqeLNbPxe1BlrQk-z0__Iw.png&quot; alt=&quot;&quot; /&gt;
In a typical data analytics platform, there are four core functions and three support functions. Core functions provide functional requirements while support functions facilitate the non-functional requirements.&lt;/p&gt;

&lt;p&gt;As part of core functions, data is ingested, stored, processed, analysed and served to business stakeholders to fulfil Data &amp;amp; AI use cases.&lt;/p&gt;

&lt;p&gt;Support functions take care of infrastructure, security, performance, scalability and delivery aspects of these use cases.&lt;/p&gt;

&lt;p&gt;Let’s have a look at each one of them:&lt;/p&gt;

&lt;h2 id=&quot;data-ingestion&quot;&gt;Data Ingestion&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*CrN_yrcBei0le6t_4mHf2g.png&quot; alt=&quot;&quot; /&gt;
Data Ingestion deals with all the challenges related to incoming data. Its a framework that makes it easier to collect and integrate data from different types of data sources and support different types of data transport protocols.&lt;/p&gt;

&lt;p&gt;Some of the challenges faced here are: multiple source ingestion, managing streaming/real-time data, speed of ingestion, change detection.&lt;/p&gt;

&lt;h2 id=&quot;data-storage&quot;&gt;Data Storage&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*DQF7xxPaLroHsoCCahxHWw.png&quot; alt=&quot;&quot; /&gt;
Once you have ingested data into your platform, you need to store it somewhere. There are different types of storages/databases and we select specific storages/databases keeping various factors in mind like data type, ingestion type, processing and request types.&lt;/p&gt;

&lt;p&gt;Notable storage types used in typical data platforms are file storage, Databases, Data Warehouses, Data Lakes, Delta Lakes, Data Mesh etc.&lt;/p&gt;

&lt;h2 id=&quot;data-processing--analysis&quot;&gt;Data Processing &amp;amp; Analysis&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*qVM7MkscynGujkc0Z0opGQ.png&quot; alt=&quot;&quot; /&gt;
To draw insights from data, we may need to clean, impute, analyse, transform, aggregate it. We may need to build meaningful features in order to build useful models. All these activities are taken care of in this function.&lt;/p&gt;

&lt;p&gt;Data engineering, Big Data processing, Business Intelligence, Machine Learning and Artificial Intelligence capabilities are applied to the data as part of this function.&lt;/p&gt;

&lt;p&gt;Apart from raw data, we may need to store intermediate data or derived insights in order to consume it later. Hence processing, analysis and storage functions may be used iteratively.&lt;/p&gt;

&lt;h2 id=&quot;data-service&quot;&gt;Data Service&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*zyfDIQmeGwoDrkKie5Q6bA.png&quot; alt=&quot;&quot; /&gt;
Actionable insights have to be consumed by business stakeholders and customers. Data service function takes care of hosting these insights. The type of data service can be APIs, KPI reports/dashboards, notebooks and development environments.&lt;/p&gt;

&lt;h2 id=&quot;cloud-services&quot;&gt;Cloud Services&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*2fGS-Ja0FBLpZkOMS9RbOA.png&quot; alt=&quot;&quot; /&gt;
All the above functions (as well as DevOps &amp;amp; Governance functions) can be built on-premise as well as on-cloud. Due to various benefits in terms of infrastructure, platform &amp;amp; application, the cloud has become go to support function for almost all the technology requirements.&lt;/p&gt;

&lt;p&gt;Type of cloud services is available as follows: IaaS, PaaS &amp;amp; SaaS. Major cloud providers in Data &amp;amp; AI area are AWS, Azure &amp;amp; GCP. We will learn more about these terms in upcoming posts.&lt;/p&gt;

&lt;h2 id=&quot;devops&quot;&gt;DevOps&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*RoVBPnm9SAYPfB6ibAI2Rw.png&quot; alt=&quot;&quot; /&gt;
The term DevOps is a combination of two words namely Development and Operations. DevOps is a function that allows a single team to manage the entire application development life cycle, that is, development, testing, deployment, and monitoring.&lt;/p&gt;

&lt;p&gt;The ultimate goal of DevOps is to decrease the duration of the system’s development life cycle while delivering features, fixes, and updates frequently in close synchronization with business objectives.&lt;/p&gt;

&lt;p&gt;It consists of various stages such as continuous development, continuous integration, continuous testing, continuous deployment, and continuous monitoring.&lt;/p&gt;

&lt;p&gt;Notable tools in DevOps area are Git, Jenkins, Kubernetes, Chef, Nagios etc.&lt;/p&gt;

&lt;h2 id=&quot;governance&quot;&gt;Governance&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*LTMRYLWKLJG8B2aGNcTgVg.png&quot; alt=&quot;&quot; /&gt;
Data governance is a function to manage the availability, usability, integrity and security of the data in enterprise systems, based on internal data standards and policies that also control data usage. Effective data governance ensures that data is consistent and trustworthy and doesn’t get misused.&lt;/p&gt;

&lt;p&gt;This function also includes other concepts such as Data Stewardship, Data Quality, and others to help an enterprise gain better control over its data assets, including methods, technologies, and behaviours around the proper management of data.&lt;/p&gt;

&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting It All Together&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*vR8dBkIDd_E6OvISB4vFNw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So this post, though it was a high-level view, we learnt about how actionable insights are generated from data. I believe you found this post helpful, we will dive deeper into the above components/functions in upcoming posts.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">AI Sells, Data Delivers!</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/25/AI-Sells-Data-Delivers.html" rel="alternate" type="text/html" title="AI Sells, Data Delivers!" /><published>2020-04-25T00:00:00-05:00</published><updated>2020-04-25T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/25/AI-Sells-Data-Delivers</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/25/AI-Sells-Data-Delivers.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*oneAF1ru_QWnIb775r0wmw.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;
&lt;p&gt;The world has advanced at a faster pace and new technologies are reshaping the business world and society. One of these emerging technologies, Artificial Intelligence (AI), has gained immense momentum in the world like other technologies such as the IoT, Blockchain, 3D printing, Robotics etc.&lt;/p&gt;

&lt;p&gt;AI is all around us these days, both in areas that border on science fiction, like self-driving cars to the more ordinary tasks like what show should you watch or purchase next. AI is influencing almost every walk of life, from businesses to society. With these technologies, the business will gain more agility needed to solve problems that humans can’t possibly solve.&lt;/p&gt;

&lt;h2 id=&quot;three-components-ofai&quot;&gt;Three Components of AI&lt;/h2&gt;
&lt;p&gt;Apart from the context of the domain where AI is being applied, there are three main components of AI:
&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*nqj3UWtlGvTq8oy2m0c10w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first one is the AI algorithm itself. Open-source machine learning libraries like Keras, Theano and TensorFlow have shed a lot of the low-level complexity involved in designing and building AI applications. These tools are free, well documented and supported by vibrant communities. The availability of these tools has made building AI applications far more accessible to developers.&lt;/p&gt;

&lt;p&gt;The second one is computing power, both in the form of raw CPU power and large scale data storage solutions. Cloud services like Amazon Web Services, Google Cloud, Microsoft Azure and others make renting servers, virtual machines and big data tools are as simple as pushing a few buttons.&lt;/p&gt;

&lt;p&gt;The third but the most important one is data. Before you can contemplate hiring data scientists, renting or paying for servers and installing open-source machine learning libraries, you must have data. The quality and depth of data will determine the level of AI applications you can achieve.&lt;/p&gt;

&lt;h2 id=&quot;data-ai&quot;&gt;Data &amp;amp; AI&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*OyUtvGybX6HYZGWHy4DvaA.png&quot; alt=&quot;&quot; /&gt;
Source: https://www.ibm.com/cloud/garage/architectures/dataAnalyticsArchitecture&lt;/p&gt;

&lt;p&gt;While AI is a reasonably wide area of study in computer science, most of the excitement these days is centred on an area of AI called machine learning and in particular, deep learning. Machine learning trains the algorithms to learn and predict answers to problems by analysing data to make predictions on their own.&lt;/p&gt;

&lt;p&gt;As we discussed above, the promise of AI depends on certain ingredients for successful adoption; one of the critical ingredients for a successful AI implementation is a clean, representative and large amount of historical data. However, unless you are Google or Facebook with vast amounts of representative data, you will struggle to harvest historical data that are enough to give the required inference for machine learning techniques to be an effective enabler for AI initiatives. Therefore, to make AI work, there is a need for an improved level of data preparation, engineering, enrichment, and contextualization.&lt;/p&gt;

&lt;p&gt;As with most reports about groundbreaking technology, this discussion is way ahead of current industry practices. The vision serves a useful purpose in suggesting what’s possible. But with many businesses lacking the data infrastructure necessary to obtain real AI and ML capabilities, the journey towards perfect production can also be so abstract that it perplexes the very people looking to achieve it.&lt;/p&gt;

&lt;p&gt;AI algorithms learn from data. It is critical that you feed them the right data for the problem you want to solve. Even if you have good data, you need to make sure that it is on a useful scale, format and even that meaningful features are included. Understand the key capabilities you need for collaborative, operational data preparation pipelines to serve the needs of both your data and business analysts.&lt;/p&gt;

&lt;p&gt;During the global launch of the Outside Insight book, author and Meltwater CEO Jorn Lyseggen, alongside AI experts, discussed the importance of the data fueling AI, and the need for executives using AI outputs for decision-making to both understand the data informing those outputs and ensure it’s as comprehensive and unbiased as possible.&lt;/p&gt;

&lt;p&gt;“Artificial Intelligence is your rocket, but data is the fuel. You can have the best algorithms in the world, an amazing rocket, but you’re only going to get as far as your data gets you. Data is fundamental - data is AI,” said Gerardo Salandra, Chairman of the AI Society of Hong Kong and CEO at Rocketbots, at the Hong Kong launch event.&lt;/p&gt;

&lt;p&gt;Similarly, Monica Rogati’s Data Science Hierarchy of Needs is a pyramid showing what’s necessary to add intelligence to the production system. At the bottom is the need to gather the right data, in the right formats and systems, and in the right quantity. Any application of AI and ML will only be as good as the quality of data collected.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/0*gMTiDUjK4OFz2KHA.jpg&quot; alt=&quot;&quot; /&gt;
Source: https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007&lt;/p&gt;

&lt;p&gt;In the growing AI market, International Data Corporation (IDC) predicts global spending is expected to increase 50% per year, to a total of $57.6 billion by 2021. Business leaders are catching on to the importance of implementing an AI strategy globally. However, it’s not enough just to introduce AI-driven tools; you need the right data inputs to find valuable insights.&lt;/p&gt;

&lt;h2 id=&quot;importance-ofdata&quot;&gt;Importance of Data&lt;/h2&gt;
&lt;p&gt;A lot has been written about AI recently, but one element that is often not stressed is the value data plays in allowing AI to function. Take self-driving cars - probably the most recognized application of AI. Building a self-driving car requires a humongous amount of data ranging from signals from infrared sensors, images from digital cameras, and high-resolution maps. NVIDIA estimates that one self-driving car generates 1 TB per hour of raw data. All that data is then used in the development of the AI models that actually drive the car.&lt;/p&gt;

&lt;p&gt;While we have seen recent advances in other AI techniques like reinforcement learning that use less data (like the success of Deep Mind’s recent Alpha Go - Zero in the game of GO), data is still critical for developing AI applications.&lt;/p&gt;

&lt;p&gt;Enterprises are overwhelmed with silo IT systems built over the years that contain data designed to do very specific individual ‘System of Record’ tasks, but unfortunately, these records are duplicated across multiple ‘Systems of Record’ resulting in massive data proliferation but lacking complete representation of an entity in any single system. This reality has given rise to fragmented and often duplicated data landscape that requires expensive and often non-efficient means of establishing ‘Source of Truth’ data sets.&lt;/p&gt;

&lt;h2 id=&quot;data-provides-intelligence-toai&quot;&gt;Data provides ‘Intelligence’ to AI&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*KnXVRW53ATJeiTMbVAG4QA.png&quot; alt=&quot;&quot; /&gt;
AI applications improve as they gain more experience (means more data) but present AI applications have an unhealthy infatuation with gaining this experience exclusively from Machine Learning techniques. While there is nothing inherently wrong with Machine Learning, the main caveat for a successful Machine Learning outcome is sufficient and representative historical data for the machine to learn from. For example, if an AI model is learning to recognize chairs and has only seen standard dining chairs that have four legs, the model may believe that chairs are only defined by four legs. This means if the model is shown to, say, a desk chair that has one pillar, it will not recognize it as a chair.&lt;/p&gt;

&lt;h2 id=&quot;preparing-data-forai&quot;&gt;Preparing data for AI&lt;/h2&gt;
&lt;p&gt;While your organisation may not be at the stage where you are able to start building AI applications, at the least you should be preparing for a future where your data will be utilised to power smart solutions. Treat every new initiative or project as an opportunity to build a foundation for future data models.&lt;/p&gt;

&lt;h3 id=&quot;data-collection&quot;&gt;Data Collection&lt;/h3&gt;
&lt;p&gt;This aspect has become crucial in light of the GDPR legislation. Are there clear and followed guidelines about what and why data is collected when a new feature or product is being developed? Does that data have a purpose or is it being collected just like that?&lt;/p&gt;

&lt;h3 id=&quot;data-format&quot;&gt;Data Format&lt;/h3&gt;
&lt;p&gt;When you are collecting data, is it being saved in a usable format across all our data collection touchpoints? Are the field names the same? Is the same level of validation and error checking applied across products?&lt;/p&gt;

&lt;h3 id=&quot;data-storage&quot;&gt;Data Storage&lt;/h3&gt;
&lt;p&gt;Data needs to be flowing into data stores and be available in real-time to all areas of the business. Given that AI applications usually become more reliable the more they can correlate different sources of information, siloed data sets that are hard to access become an obstacle to discovering value in an organisation’s data.&lt;/p&gt;

&lt;h3 id=&quot;data-literacy&quot;&gt;Data Literacy&lt;/h3&gt;
&lt;p&gt;AI is basically biased in how it was created, trained, programmed. One of the most significant things for AI to be successful is that executives and decision-makers have the data literacy to beat up the model, to challenge the model, to massage the model and to fully understand what the underlying assumptions are to make sure the answer it produces actually matches the terrain that you want to operate in. What’s vital to get the best predictive models and forward-looking insights is that the data informing them comes from a variety of external sources.&lt;/p&gt;

&lt;h3 id=&quot;more-data&quot;&gt;More Data&lt;/h3&gt;
&lt;p&gt;Just like humans, AI applications improve with more experience. Data provides examples essential to train models that can perform predictions and classifications. A good example of this is in image recognition. The availability of data through ImageNet transformed the pace of change in image understanding and led to computers reaching human-level performance. A general rule of thumb is that you need 10 times as much data as the number of parameters (i.e., degrees of freedom) in the model being built. The more complicated the task, the more data needed.&lt;/p&gt;

&lt;h3 id=&quot;data-understanding&quot;&gt;Data Understanding&lt;/h3&gt;
&lt;p&gt;For cooking the perfect meal, it’s great to know the tastes of your diners. Similarly, data is essential to tailoring an AI model to the wants of specific users. We need to learn how users use their applications and search content in order to generate meaningful personalized recommendations.&lt;/p&gt;

&lt;p&gt;By knowing what content users read, download and collect, we can give them advice on potential content of interest. Furthermore, techniques such as collaborative filtering, which make suggestions based on the similarity between users, improve with access to more data; the more user data one has, the more likely it is that the algorithm can find a similar a user.&lt;/p&gt;

&lt;h3 id=&quot;diverse-data&quot;&gt;Diverse Data&lt;/h3&gt;
&lt;p&gt;A key problem in building AI models is overfitting - this is, where the model focuses too specifically on the examples given. For instance, if a model is trying to learn to recognize chairs and has only been shown standard dining chairs with four legs, it may learn that chairs are defined by having four legs. If the model is then shown a desk chair with just one pillar, it wouldn’t recognize it. Having diverse data helps combat this problem.&lt;/p&gt;

&lt;p&gt;During training, the AI model can view more examples of different types of things. This is particularly valuable in working with data about people, where there can be the potential for algorithmic bias against people from diverse backgrounds. This point was made by Prof. Dame Wendy Hall in her interview at the World Summit AI. Prof. Hall focused on the need to make sure that AI was trained on diverse datasets. A good example of combating this through data is the lengths that Apple went to in training their new Face ID recognition algorithm.&lt;/p&gt;

&lt;h3 id=&quot;external-data&quot;&gt;External Data&lt;/h3&gt;
&lt;p&gt;As the race to implement AI tools at an enterprise-level reaches new heights, it’s important to note that the data informing those tools is of paramount importance. Relying only on internal information to inform algorithms will produce insights gleaned only from the information you already have. Rather, it’s vital that decision-makers also look to insights from external data for a much more comprehensive and unbiased view of their customers and industry landscape.&lt;/p&gt;

&lt;h3 id=&quot;hypothesis-testing&quot;&gt;Hypothesis Testing&lt;/h3&gt;
&lt;p&gt;Even in cases where techniques can be used that require less training data, more data makes it easier to test AI systems. An example of this is A/B testing. This is where a developer takes a small amount of traffic to a site and tests to see whether a new recommendation engine or search algorithm performs better on that small set of traffic.&lt;/p&gt;

&lt;p&gt;The more traffic (means data), the easier it is to test multiple algorithms or variants. At the World AI Summit, Netflix explained how they use A/B testing to select artwork that maximizes the engagement with films and TV series on Netflix.&lt;/p&gt;

&lt;h3 id=&quot;data-reusability&quot;&gt;Data Reusability&lt;/h3&gt;
&lt;p&gt;Finally, it is usually the case that data can be reused for different applications. For example, a technique called transfer learning allows data developed for one domain to be applied to another domain. Moreover, recent work has revealed that background knowledge can further improve on tasks like object detection in images. Recent work from Google has shown how training using data designated for a different task like image recognition can help performance on another completely different task like language translation.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In summary, data is the pivotal element in developing any AI system today.&lt;/p&gt;

&lt;p&gt;In the near future, what we are now calling AI will be embedded in our culture and we won’t call it AI any longer. It will just be how things work. What you have in your control today is your data. It’s crucial that you start preparing for a future where AI applications can start using your data and that starts with the quantity and quality of the data itself.&lt;/p&gt;

&lt;p&gt;Embracing AI with business &amp;amp; society is a journey, not a silver bullet that will solve challenges instantly. It begins with gathering data into simple visualizations and statistical processes that allow you to better understand your data and get your processes under control. From there, you’ll progress through increasingly advanced analytical capabilities, until you achieve that utopian aim of perfect production, where you have AI helping you make products as efficiently and reliably as possible.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Data &amp;amp; AI Platforms — Open Source Vs Managed Services</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/20/Data-AI-Platforms-Open-Source-Vs-Managed-Services.html" rel="alternate" type="text/html" title="Data &amp; AI Platforms — Open Source Vs Managed Services" /><published>2020-04-20T00:00:00-05:00</published><updated>2020-04-20T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/20/Data-AI-Platforms-Open-Source-Vs-Managed-Services</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/20/Data-AI-Platforms-Open-Source-Vs-Managed-Services.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*Svz8nTTFVj8OAdZMhrCiiQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While designing and building Data &amp;amp; AI platforms, you may need to evaluate the options available. Whether your platform would be on-premise or you could use cloud/s services or you would take a hybrid approach.
In any case, you may need to look and evaluate various tools &amp;amp; services for your ingestion, storage, process/analysis and serving layers.
In this post, I have mapped open-source and popular managed cloud services to make our evaluation process a bit easier.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*-lxchArCT3aAPsBWjS-cBQ.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*0wyyPh2jLjFs9-e5YRE4UA.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*29JnAqIQuw58X1OCYGPROg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I will be comparing these services with their pros and cons and when to use which service in upcoming posts, stay tuned.
I hope you find this post useful, stay tuned for more, any feedback would be highly appreciated.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Architecting Modern Data Platforms</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/15/Architecting-Modern-Data-Platforms.html" rel="alternate" type="text/html" title="Architecting Modern Data Platforms" /><published>2020-04-15T00:00:00-05:00</published><updated>2020-04-15T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/15/Architecting-Modern-Data-Platforms</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/15/Architecting-Modern-Data-Platforms.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*XY87VHW3-cJGMb7XNfUZRQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-architecture-principles&quot;&gt;Data Architecture Principles&lt;/h2&gt;

&lt;p&gt;Whether you are responsible for data, systems or application architecture, you need to define some principles to help you navigate the fast-paced modern world. Data Architecture Principles are the foundation for data architecture that will allow your business to run at an optimized level today, and into the future.&lt;/p&gt;

&lt;h3 id=&quot;adhere-to-adda-accessibility-definition-decoupling-agility&quot;&gt;Adhere to ADDA (Accessibility, Definition, Decoupling, Agility)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*nUhGoJeLJvDz8B8mcAlgig.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Data Accessibility is critical for the success of any business. Easily accessible data enables you to move quickly, focus on the product, and build a data-informed pipeline where data leads to better decisions and actions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Definition or Catalog helps analysts and other data users to find the data that they need, serves as an inventory of available data, and provides information to evaluate fitness data for intended uses.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Decoupling helps in design since it allows each data layer to be independent of other data layers.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Agility is when your data can move at the speed of your business. For companies to achieve true data agility, they need to be able to access the data they need, when and where they need it.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So the first data architecture principle is to make sure that business data is accessible, defined, decoupled and agile.&lt;/p&gt;

&lt;h3 id=&quot;design-for-rsm-reliability-scalability-maintainability&quot;&gt;Design for RSM (Reliability, Scalability, Maintainability)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*B5TsIF4HDMEo_JRuMHOhWw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reliability means the data systems we are designing work correctly and fault-tolerant up to some level.&lt;/li&gt;
  &lt;li&gt;Scalability means data systems are adaptable to growth in a linear way.&lt;/li&gt;
  &lt;li&gt;Maintainability means that data systems remain easier to maintain.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Second data architecture principle is that the data systems remain reliable, scalable and maintainable over time.&lt;/p&gt;

&lt;h3 id=&quot;use-right-tools&quot;&gt;Use Right Tools&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*lfW4KerKIMivkID8Cc9noA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We need to use the right tool at each data layer by aligning the choice to the data structure, latency and throughput requirements and access patterns.&lt;/p&gt;

&lt;h3 id=&quot;cloud-nativeagnostic&quot;&gt;Cloud-Native/Agnostic&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*_I3Ge-AIWtFBvyH7_21IUw.png&quot; alt=&quot;&quot; /&gt;
Whether you have the data on-premise or you are using single/multiple cloud service providers, each decision has its own pros &amp;amp; cons.&lt;/p&gt;

&lt;h3 id=&quot;be-cost-conscious&quot;&gt;Be Cost-Conscious&lt;/h3&gt;
&lt;p&gt;Cost of building complex and ever-evolving data systems can be huge, we need to make sure we use available resources efficiently.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Efficient consumption of services&lt;/li&gt;
  &lt;li&gt;Select cost-conscious options&lt;/li&gt;
  &lt;li&gt;Enforce policies and controls&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-lake-basics&quot;&gt;Data Lake Basics&lt;/h2&gt;
&lt;p&gt;Data Lake is becoming the defacto standard in modern data platforms, let’s have a look at what it is and how it helps to build modern data systems.&lt;/p&gt;

&lt;h3 id=&quot;data-lake-definition&quot;&gt;Data Lake Definition&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An architectural approach&lt;/li&gt;
  &lt;li&gt;Massive heterogeneous data stored centrally&lt;/li&gt;
  &lt;li&gt;Available to the diverse group of users&lt;/li&gt;
  &lt;li&gt;To be categorized, processed, analyzed &amp;amp; consumed&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-lake-characteristics&quot;&gt;Data Lake Characteristics&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Structured, semi-structured &amp;amp; unstructured data&lt;/li&gt;
  &lt;li&gt;Scaled out as required&lt;/li&gt;
  &lt;li&gt;The diverse set of storage, analytics and ML/AI tools&lt;/li&gt;
  &lt;li&gt;Designed for low-cost storage and analytics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;high-level-architecture&quot;&gt;High-Level Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*ydcHHJxlQZJc7bRsFEy-qw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A typical data analytics platform takes business raw data as input and provides actionable insights. It has four layers: ingest, store, process/analyse &amp;amp; serve.
Let’s have a look at each data layer in detail:&lt;/p&gt;

&lt;h2 id=&quot;data-characteristics&quot;&gt;Data Characteristics&lt;/h2&gt;

&lt;h3 id=&quot;ingest&quot;&gt;Ingest&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Data can be ingested from a variety of data sources like web/mobile apps, databases, application logging, messaging and IOT devices.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*gqnD79N34Epji2EZklZ0eg.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Data can be hot, warm or cold based on its velocity, request rates and latency requirements:
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*xMOM4kkrQZ4WosF9x0kwXQ.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Data can be categorized based on data structures and access-pattern requirements. Based on these characteristics, we decide how to store and process each type of data.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*rPI43SQbQCvb6H70PeId8A.png&quot; alt=&quot;&quot; /&gt;
    &lt;h3 id=&quot;storage&quot;&gt;Storage&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;How we are going to store data depends mainly on two major factors:&lt;/li&gt;
  &lt;li&gt;What is the structure of the data?&lt;/li&gt;
  &lt;li&gt;What is the frequency and usage of data?
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*AKhZoJXjcb5ue9rfgWXe3Q.png&quot; alt=&quot;&quot; /&gt;
    &lt;h3 id=&quot;analytics-types&quot;&gt;Analytics Types&lt;/h3&gt;
    &lt;p&gt;There can be different kind of analytics you may need to perform based on the structure and access-patterns of data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Message/Stream Analysis&lt;/li&gt;
  &lt;li&gt;Interactive Analysis&lt;/li&gt;
  &lt;li&gt;Batch Analysis&lt;/li&gt;
  &lt;li&gt;Machine Learning/AI&lt;/li&gt;
  &lt;li&gt;ETL Processing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Store and Process/Analyse steps can be performed iteratively as after processing or analysing the results, you may need to store data in the processed form before acting further.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*zRYSvV-JLCwG3rIf6etUdg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;serve&quot;&gt;Serve&lt;/h3&gt;
&lt;p&gt;There may be various ways of serving insights to end-user (business, data scientists or developers).&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Applications &amp;amp; APIs&lt;/li&gt;
  &lt;li&gt;Analysis &amp;amp; Visualization&lt;/li&gt;
  &lt;li&gt;Notebooks&lt;/li&gt;
  &lt;li&gt;IDEs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting It All Together&lt;/h2&gt;
&lt;p&gt;Now let’s combine what we have discussed till now, you may notice that ‘Security and Governance’ process needs to be applied across the data layers along with Data Catalog.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*-H4qKZwKOxYHtIgyRLh8fw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;product-driven-data-architecture&quot;&gt;Product-Driven Data Architecture&lt;/h2&gt;
&lt;p&gt;While data lake is the defacto standard these days, still there are few issues that are to be addressed like ubiquitous data and source proliferation, innovation agenda and consumer proliferation, coupled pipeline decomposition.
Recently, Zhamak Dehghani has proposed a data architecture to move beyond a monolithic data lake to a distributed data mesh which can possibly address above mentioned concerns.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*GOP7DOIVIOZ_oBVnRksWbg.png&quot; alt=&quot;&quot; /&gt;
https://martinfowler.com/articles/data-monolith-to-mesh.html&lt;/p&gt;

&lt;h2 id=&quot;reference-architecture&quot;&gt;Reference Architecture&lt;/h2&gt;
&lt;p&gt;Before signing off, let’s also have a look at reference data architecture from leading cloud services providers like Azure, AWS and GCP.&lt;/p&gt;

&lt;h3 id=&quot;reference-architecture--azure&quot;&gt;Reference Architecture — Azure&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*SZ896yzUQfJlYuclLUf8Ow.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;reference-architecture--aws&quot;&gt;Reference Architecture — AWS&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*sMSQEc9_L8wm2DpxzsknEg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;reference-architecture--gcp&quot;&gt;Reference Architecture — GCP&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*LihkT8HW_U5b8c4V14-n2A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I hope you find this post useful, stay tuned for more, any feedback would be highly appreciated.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">5 Tips for DS/AI Beginners &amp;amp; Enthusiasts</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/26/5-tips-for-ds-ai-beginners-enthusiasts.html" rel="alternate" type="text/html" title="5 Tips for DS/AI Beginners &amp; Enthusiasts" /><published>2020-03-26T00:00:00-05:00</published><updated>2020-03-26T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/26/5-tips-for-ds-ai-beginners-enthusiasts</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/26/5-tips-for-ds-ai-beginners-enthusiasts.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*WYAntO3ZfXBMkyn31mHoRw.jpeg&quot; alt=&quot;Photo by [Sam Truong Dan](https://unsplash.com/@sam_truong?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/tips?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In this post, I am sharing 5 important tips for budding data scientists, there is a bonus tip as well in the end.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;While I believe that the more you struggle, the more you get to learn in the process, you can still learn from experienced professionals to avoid common roadblocks or challenges.&lt;/p&gt;

&lt;p&gt;DS/AI starters and enthusiasts keep interacting with me and I try to help them. Apart from common questions by them, I give them tips on how they can become effective in their DS/AI journey, i.e. what to focus and what to avoid etc.&lt;/p&gt;

&lt;p&gt;Here I am sharing 5 of those tips:&lt;/p&gt;

&lt;h2 id=&quot;master-thebasics&quot;&gt;Master The Basics&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*KSja_FQfoEm-sRMao1VD6g.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Before you can work on any DS/AI problem, you need to master the basics. Understand the mathematics required for DS/AI, which is Linear Algebra, Multivariate Calculus, Statistics &amp;amp; Probability.&lt;/p&gt;

&lt;p&gt;Then learn about frequently used algorithms like Logistic Regression, Naive Bayes, Decision Trees, Random Forest etc. Where to apply which algorithm and what are the advantages and limitations of using a particular algorithm.&lt;/p&gt;

&lt;p&gt;Understand the overall process of working in DS/AI projects, from defining the problem to deploying the solution.&lt;/p&gt;

&lt;p&gt;Improve your coding skills to execute &amp;amp; validate your hypothesis efficiently. Python &amp;amp; R are the two major languages preferred by data scientists.&lt;/p&gt;

&lt;h2 id=&quot;learn-justenough&quot;&gt;Learn Just Enough&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*WzniU-FFsxpxKx5aglBU1g.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DS/AI is a vast field, one can not be an expert overnight. The biggest mistake newbies do is to get stuck into an endless learning loop.&lt;/p&gt;

&lt;p&gt;You are learning DS/AI is to solve real-world problems, so learn just enough concepts to get started. Participate in hackathons/competitions, practice on public datasets.&lt;/p&gt;

&lt;p&gt;You need not read each book or attend every course on the planet before feeling confident to start with DS/AI. Just follow one decent book or course to build your basics and start working on problems. Keep the material (books &amp;amp; courses) for reference in case you get stuck with your problem.&lt;/p&gt;

&lt;h2 id=&quot;handle-data-like-apro&quot;&gt;Handle Data Like a Pro&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*YAYqqk7M7wQ28U7sVh1oQA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Data is the heart of DS/AI initiatives &amp;amp; projects. If you can’t handle data, you can’t make progress with your use case. Data handling can make or break any DS/AI project.&lt;/p&gt;

&lt;p&gt;Build your skills in data handling, learn frequently used tips &amp;amp; tricks in SQL, Pandas (in Python) or data.table (in R) to handle &amp;amp; manipulate data efficiently.&lt;/p&gt;

&lt;p&gt;Learn from Kaggle kernels, popular GitHub repos, how experts handle the data. Gather and clean public datasets on your own and refer these resources wherever get stuck.&lt;/p&gt;

&lt;h2 id=&quot;understand-thecontext&quot;&gt;Understand The Context&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*ChpN6CWwu61TEP-V.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As a newbie data scientist, you may be tempted to get the highest accuracy you can on any DS/AI problem you are working. But the real world is quite different, it’s not about the accuracy every time, many times robustness is very important and most of the time, the business may need models to be more interpretable.&lt;/p&gt;

&lt;p&gt;Every framework, every feature has its own use case. If a particular approach worked in your previous project, the same may not work in the current one. As we say, there is no silver bullet in DS/AI field.&lt;/p&gt;

&lt;p&gt;Hence understanding the context of the problem or the use case is important.&lt;/p&gt;

&lt;h2 id=&quot;improve-communication&quot;&gt;Improve Communication&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*9ZDJW08N1FZlPIFu.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To understand the problem or use case, to get the overall context from business, to explain outcomes of your complex models requires excellent communication skills.&lt;/p&gt;

&lt;p&gt;Presenting your approaches and findings to a non-technical audience, such as the marketing team or the CXOs, is a crucial part of being a data scientist.&lt;/p&gt;

&lt;p&gt;You need to have the ability to interpret data, tell the stories contained therein, and in general, communicate, write and present well. Presentation, Storytelling, Data Visualization, Writing/Publishing, Business Insights, all are part of communication skills.&lt;/p&gt;

&lt;p&gt;You may have to work hard to develop these skills — the same as you would with any technical skills. But with time and practice, you can get really good at it.&lt;/p&gt;

&lt;h2 id=&quot;bonus-tip-develop-t-shaped-skill-set&quot;&gt;Bonus Tip: Develop T-shaped Skill-set&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*5VE1BaIQGTmXCxIx.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DS/AI is an interdisciplinary field, and you can get expertise in one area at a time. Still, I would suggest you develop T-shaped skill-set to collaborate better with experts in other related fields working with you in the project.&lt;/p&gt;

&lt;p&gt;T-shaped skills describe specific attributes of desirable workers. The vertical bar of the T refers to expert knowledge and experience in a particular area, while the top of the T refers to an ability to collaborate with experts in other disciplines and a willingness to use the knowledge gained from this collaboration. A t-shaped person is someone with t-shaped skills.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">In this post, I am sharing 5 important tips for budding data scientists, there is a bonus tip as well in the end. While I believe that the more you struggle, the more you get to learn in the process, you can still learn from experienced professionals to avoid common roadblocks or challenges. DS/AI starters and enthusiasts keep interacting with me and I try to help them. Apart from common questions by them, I give them tips on how they can become effective in their DS/AI journey, i.e. what to focus and what to avoid etc. Here I am sharing 5 of those tips: Master The Basics Before you can work on any DS/AI problem, you need to master the basics. Understand the mathematics required for DS/AI, which is Linear Algebra, Multivariate Calculus, Statistics &amp;amp; Probability. Then learn about frequently used algorithms like Logistic Regression, Naive Bayes, Decision Trees, Random Forest etc. Where to apply which algorithm and what are the advantages and limitations of using a particular algorithm. Understand the overall process of working in DS/AI projects, from defining the problem to deploying the solution. Improve your coding skills to execute &amp;amp; validate your hypothesis efficiently. Python &amp;amp; R are the two major languages preferred by data scientists. Learn Just Enough DS/AI is a vast field, one can not be an expert overnight. The biggest mistake newbies do is to get stuck into an endless learning loop. You are learning DS/AI is to solve real-world problems, so learn just enough concepts to get started. Participate in hackathons/competitions, practice on public datasets. You need not read each book or attend every course on the planet before feeling confident to start with DS/AI. Just follow one decent book or course to build your basics and start working on problems. Keep the material (books &amp;amp; courses) for reference in case you get stuck with your problem. Handle Data Like a Pro Data is the heart of DS/AI initiatives &amp;amp; projects. If you can’t handle data, you can’t make progress with your use case. Data handling can make or break any DS/AI project. Build your skills in data handling, learn frequently used tips &amp;amp; tricks in SQL, Pandas (in Python) or data.table (in R) to handle &amp;amp; manipulate data efficiently. Learn from Kaggle kernels, popular GitHub repos, how experts handle the data. Gather and clean public datasets on your own and refer these resources wherever get stuck. Understand The Context As a newbie data scientist, you may be tempted to get the highest accuracy you can on any DS/AI problem you are working. But the real world is quite different, it’s not about the accuracy every time, many times robustness is very important and most of the time, the business may need models to be more interpretable. Every framework, every feature has its own use case. If a particular approach worked in your previous project, the same may not work in the current one. As we say, there is no silver bullet in DS/AI field. Hence understanding the context of the problem or the use case is important. Improve Communication To understand the problem or use case, to get the overall context from business, to explain outcomes of your complex models requires excellent communication skills. Presenting your approaches and findings to a non-technical audience, such as the marketing team or the CXOs, is a crucial part of being a data scientist. You need to have the ability to interpret data, tell the stories contained therein, and in general, communicate, write and present well. Presentation, Storytelling, Data Visualization, Writing/Publishing, Business Insights, all are part of communication skills. You may have to work hard to develop these skills — the same as you would with any technical skills. But with time and practice, you can get really good at it. Bonus Tip: Develop T-shaped Skill-set DS/AI is an interdisciplinary field, and you can get expertise in one area at a time. Still, I would suggest you develop T-shaped skill-set to collaborate better with experts in other related fields working with you in the project. T-shaped skills describe specific attributes of desirable workers. The vertical bar of the T refers to expert knowledge and experience in a particular area, while the top of the T refers to an ability to collaborate with experts in other disciplines and a willingness to use the knowledge gained from this collaboration. A t-shaped person is someone with t-shaped skills. Ankit Rathi is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture. Why don’t you connect with Ankit on YouTube, Twitter, LinkedIn or Instagram?</summary></entry></feed>