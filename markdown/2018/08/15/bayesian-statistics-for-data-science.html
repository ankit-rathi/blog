<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Bayesian Statistics for Data Science | Data Intelligence</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Bayesian Statistics for Data Science" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Probability &amp; Statistics for Data Scientists" />
<meta property="og:description" content="Probability &amp; Statistics for Data Scientists" />
<link rel="canonical" href="https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html" />
<meta property="og:url" content="https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html" />
<meta property="og:site_name" content="Data Intelligence" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-08-15T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Probability &amp; Statistics for Data Scientists","@type":"BlogPosting","url":"https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html","dateModified":"2018-08-15T00:00:00-05:00","datePublished":"2018-08-15T00:00:00-05:00","headline":"Bayesian Statistics for Data Science","mainEntityOfPage":{"@type":"WebPage","@id":"https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ankit-rathi.github.io/blog/feed.xml" title="Data Intelligence" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-36087136-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Bayesian Statistics for Data Science | Data Intelligence</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Bayesian Statistics for Data Science" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Probability &amp; Statistics for Data Scientists" />
<meta property="og:description" content="Probability &amp; Statistics for Data Scientists" />
<link rel="canonical" href="https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html" />
<meta property="og:url" content="https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html" />
<meta property="og:site_name" content="Data Intelligence" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-08-15T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Probability &amp; Statistics for Data Scientists","@type":"BlogPosting","url":"https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html","dateModified":"2018-08-15T00:00:00-05:00","datePublished":"2018-08-15T00:00:00-05:00","headline":"Bayesian Statistics for Data Science","mainEntityOfPage":{"@type":"WebPage","@id":"https://ankit-rathi.github.io/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://ankit-rathi.github.io/blog/feed.xml" title="Data Intelligence" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-36087136-2','auto');ga('require','displayfeatures');ga('send','pageview');</script>



<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Data Intelligence</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/home/">ankitrathi.com</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Bayesian Statistics for Data Science</h1><p class="page-description">Probability &amp; Statistics for Data Scientists</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2018-08-15T00:00:00-05:00" itemprop="datePublished">
        Aug 15, 2018
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p><img src="https://cdn-images-1.medium.com/max/1200/1*qO6IpQH_zrwOon9FBGkJZg.png" alt="Bayesian Statistics for Data Science"></p>

<p><em>This is the 5th post of blog post series ‘</em><a href="https://www.ankitrathi.com/post/probability-statistics-for-data-science-series"><em>Probability &amp; Statistics for Data Science</em></a><em>’, this post covers these topics related to Bayesian statistics and their significance in data science.</em></p>

<ul>
  <li><em>Frequentist Vs Bayesian Statistics</em></li>
  <li><em>Bayesian Inference</em></li>
  <li><em>Test for Significance</em></li>
  <li><em>Significance in Data Science</em></li>
</ul>

<hr>

<blockquote>
  <p>Visit <a href="http://ankitrathi.com/">ankitrathi.com</a> now to:</p>
</blockquote>

<blockquote>
  <p>— to read my blog posts on various topics of AI/ML</p>
</blockquote>

<blockquote>
  <p>— to keep a tab on latest &amp; relevant news/articles daily from AI/ML world</p>
</blockquote>

<blockquote>
  <p>— to refer free &amp; useful AI/ML resources</p>
</blockquote>

<blockquote>
  <p>— to buy my books on discounted price</p>
</blockquote>

<blockquote>
  <p>— to know more about me and what I am up to these days</p>
</blockquote>

<p><strong>Frequentist Vs Bayesian Statistics</strong></p>

<p>Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment. A very common flaw found in frequentist approach i.e. dependence of the result of an experiment on the number of times the experiment is repeated.</p>

<p><em>Frequentist statistics</em> suffered some great flaws in its design and interpretation which posed a serious concern in all real life problems:</p>

<ol>
  <li>p-value &amp; Confidence Interval (C.I) depend heavily on the sample size.</li>
  <li>Confidence Intervals (C.I) are not probability distributions</li>
</ol>

<p>Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*rkeLokn-gkfeOAdkrwuCWA.png" alt="Frequentist Vs Bayesian Statistics"></p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p><strong>Bayesian Inference</strong></p>

<p>To understand <em>Bayesian Inference</em>, you need to understand <em>Conditional Probability</em> &amp; <em>Bayes Theorem</em>, if you want to review these concepts, please refer my earlier post in this series.</p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p><em>Bayesian inference</em> is a method of statistical inference in which Bayes’ theorem is used to update the probability for a hypothesis as more evidence or information becomes available.</p>

<p>An important part of <em>Bayesian Inference</em> is the establishment of <em>parameters</em> and <em>models.</em> Models are the mathematical formulation of the observed events. Parameters are the factors in the models affecting the observed data. To define our model correctly , we need two mathematical models before hand. One to represent the <em>likelihood function</em> <strong>** and the other for representing the distribution of <em>prior beliefs</em></strong><em> .</em>** The product of these two gives the <em>posterior belief</em> distribution.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*n4D8BKlVCurNg1xKshTsxg.png" alt=""></p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*hblsrFOWViHS43l5YpUXeQ.png" alt="Courtesy: &lt;http://jason-doll.com/wordpress/?page_id=127&gt;"></p>

<p>[embed]https://www.youtube.com/watch?v=5NMxiOGL39M[/embed]</p>

<p><strong>Likelihood Function</strong></p>

<p>A <em>likelihood function</em> is a function of the parameters of a statistical model, given specific observed data. <em>Probability</em> describes the plausibility of a random outcome, without reference to any observed data while <em>Likelihood</em> describes the plausibility of a model parameter value, given specific observed data.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*f5k9kbt-DNH7sNVm5fZIag.png" alt="Likelihood function"></p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p><strong>Prior &amp; Posterior Belief distribution</strong></p>

<p><em>Prior Belief distribution</em> is used to represent our strengths on beliefs about the parameters based on the previous experience. <em>Posterior Belief distribution</em> is derived from multiplication of <em>likelihood function &amp; Prior Belief distribution.</em></p>

<p>As we collect more data, our posterior belief move towards prior belief from likelihood:</p>

<p><img src="https://cdn-images-1.medium.com/max/800/0*SYr-Xd8_H3I4cCX1.png" alt="Courtesy: &lt;https://jimgrange.wordpress.com/2016/01/18/pesky-priors/&gt;"></p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p><strong>Test for Significance</strong></p>

<p><strong>Bayes factor</strong></p>

<p><em>Bayes factor</em> is the equivalent of <em>p-value</em> in the <em>Bayesian</em> framework. The <em>null hypothesis</em> in Bayesian framework assumes ∞ probability distribution only at a particular value of a parameter (say θ=0.5) and a zero probability else where. The <em>alternative hypothesis</em> is that all values of θ are possible, hence a flat curve representing the distribution.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/0*XtmxBSmi0HPZ3cQN.png" alt="Courtesy: &lt;http://areshenk-research-notes.com/bayes-factors-and-stopping-rules/&gt;"></p>

<p>Using <em>Bayes Factor</em> instead of <em>p-values</em> is more beneficial in many cases since they are independent of intentions and sample size.</p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p><strong>High Density Interval (HDI)</strong></p>

<p><em>High Density Interval</em> (HDI) or <em>Credibility Interval</em> is equivalent to <em>Confidence Interval</em> (CI) in <em>Bayesian</em> framework. HDI is formed from the posterior distribution after observing the new data.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/0*PAXk4F00PpWZbv6u" alt="Courtesy: &lt;https://www.slideshare.net/ASQwebinars/bayesian-methods-in-reliability-engineering-15204318&gt;"></p>

<p>Using <em>High Density Interval</em> (HDI) instead of <em>Confidence Interval</em> (CI) is more beneficial since they are independent of intentions and sample size.</p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p>Moreover, there is a nice article published on AnalyticsVidhya on this which elaborate on these concepts with examples:</p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p><strong>Significance in Data Science</strong></p>

<p>Bayesian statistics encompasses a specific class of models that could be used for Data Science. Typically, one draws on Bayesian models for one or more of a variety of reasons, such as:</p>

<ul>
  <li>having relatively few data points</li>
  <li>having strong prior intuitions</li>
  <li>having high levels of uncertainty</li>
</ul>

<p>And there are scenarios where Bayesian statistics will perform drastically, please read following discussion for details:</p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<p><strong>References:</strong></p>

<p>[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]<br>
[embed]https://www.coursera.org/lecture/bayesian/frequentist-vs-bayesian-inference-q5CTh[/embed]</p>

<hr>

<p><a href="https://www.ankitrathi.com/"><em>Ankit Rathi</em></a> <em>is an AI architect, published author &amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.</em></p>

<p><em>Why don’t you connect with Ankit on</em> <a href="https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw"><em>YouTube</em></a><em>,</em> <a href="https://twitter.com/rathiankit"><em>Twitter</em></a><em>,</em> <a href="https://www.linkedin.com/in/ankitrathi/"><em>LinkedIn</em></a> <em>or</em> <a href="https://instagram.com/ankitrathi/"><em>Instagram</em></a><em>?</em></p>

  </div><a class="u-url" href="/blog/markdown/2018/08/15/bayesian-statistics-for-data-science.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Democratizing Data Intelligence</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/ankit-rathi" title="ankit-rathi"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/rathiankit" title="rathiankit"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
